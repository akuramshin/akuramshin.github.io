---
layout: null
redirect_from:
  - /tread
---
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Task Robustness via Re-Labelling Vision-Action Robot Data">
  <meta name="keywords" content="VLA, Data augmentation, Language following">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Task Robustness via Re-Labelling Vision-Action Robot Data</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="/tread_site/static/css/bulma.min.css">
  <link rel="stylesheet" href="/tread_site/static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="/tread_site/static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="/tread_site/static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="/tread_site/static/css/index.css">
  <link rel="icon" href="/tread_site/static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="/tread_site/static/js/fontawesome.all.min.js"></script>
  <script src="/tread_site/static/js/bulma-carousel.min.js"></script>
  <script src="/tread_site/static/js/bulma-slider.min.js"></script>
  <script src="/tread_site/static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Task Robustness via Re-Labelling <br>Vision-Action Robot Data</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://akuramshin.github.io/">Artur Kuramshin</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://ozgraslan.github.io/">Özgür Aslan</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://www.cyrusneary.com/">Cyrus Neary</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://neo-x.github.io/">Glen Berseth</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Mila — Quebec AI Institute,</span>
            <span class="author-block"><sup>2</sup>Université de Montréal,</span>
            <span class="author-block"><sup>3</sup>The University of British Columbia</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="margin-top: 10px;">Workshop on Making Sense of Data in Robotics: Composition, Curation, and Interpretability at Scale<br> <b>CoRL 2025</b></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=M6M5W0lmaY"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/real-lab/tread_annotations"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="/assets/fonts/hf-logo.svg" alt="Hugging Face Logo" style="height: 1.75em;">
                  </span>
                  <span>Data</span>
                </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <div class="columns is-centered">
          <div class="column is-four-fifths">
               
            <div class="publication-gif">
                <figure>
                  <img src="/tread_site/static/gifs/teaser.gif" alt="Method Figure" width="100%">
                  <figcaption class="publication-caption">
                      <p style="text-align: center;""> We leverage large-scale pretrained VLMs via a three stage process: </p>
                      <p>1.) Prompt the VLM to decompose the original task into semantic sub-tasks, using the instruction and first frame for context.</p> 
                      <p>2.) process the full trajectory video to identify temporal boundaries where each sub-task occurs.</p>
                      <p>3.) Generate diverse paraphrases for each sub-task instruction, grounded in the visual context. This creates richer descriptions incorporating object attributes and spatial relationships.</p> 
                          
                      <p style="margin-top: 10px;"><strong>TREAD</strong> is a scalable framework for augmenting existing robotics datasets into more granular language-action segments, effectively increasing the diversity of our training data without requiring additional data collection.</p>

                      </figcaption>
                </figure>
              </div>
          </div>
        </div>

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The recent trend in scaling models for robot
            learning has resulted in impressive policies that can perform
            various manipulation tasks and generalize to novel scenarios.
            However, these policies continue to struggle with following
            instructions, likely due to the limited linguistic and action
            sequence diversity in existing robotics datasets. 
          </p>
          <p>
            This paper
            introduces <strong>T</strong>ask <strong>R</strong>obustness via R<strong>E</strong>-Labelling Vision-<strong>A</strong>ction
            Robot <strong>D</strong>ata (TREAD), a scalable framework that leverages
            large Vision-Language Models (VLMs) to augment existing
            robotics datasets without additional data collection, harnessing
            the transferable knowledge embedded in these models. Our
            approach leverages a pretrained VLM through three stages:
            generating semantic sub-tasks from original instruction labels
            and initial scenes, segmenting demonstration videos conditioned
            on these sub-tasks, and producing diverse instructions that
            incorporate object properties, effectively decomposing longer
            demonstrations into grounded language-action pairs. We further enhance robustness by augmenting the data with linguistically diverse versions of the text goals. Evaluations on LIBERO
            demonstrate that policies trained on our augmented datasets
            exhibit improved performance on novel, unseen tasks and
            goals. Our results show that TREAD enhances both planning
            generalization through trajectory decomposition and languageconditioned policy generalization through increased linguistic
            diversity.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div id="tooltip" class="tooltip"></div>
  <div class="container is-max-desktop">

    <div class="columns is-centered">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Example Segmentations of BridgeData V2</h2>
          <div id="grid-bridgedata" class="grid"></div>
          <div id="pagination-bridgedata" class="pagination"></div>
        </div>
    </div>

    <div class="columns is-centered" style="margin-top: 50px;">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Example Segmentations of LIBERO 90</h2>
          <div id="grid-libero" class="grid"></div>
          <div id="pagination-libero" class="pagination"></div>
        </div>
    </div>

  </div>
</section>

<!-- Results section -->
<section class="section">
  <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Results</h2>

      <div class="publication-image">
          <figure>
            <img src="/tread_site/static/images/results.png" alt="Method Figure" width="100%">
            
          </figure>
      </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
        kuramshin2025task,
        title={Task Robustness via Re-Labelling Vision-Action Robot Data},
        author={Artur Kuramshin and Ozgur Aslan and Cyrus Neary and Glen Berseth},
        booktitle={Workshop on Making Sense of Data in Robotics: Composition, Curation, and Interpretability at Scale at CoRL 2025},
        year={2025},
        url={https://openreview.net/forum?id=M6M5W0lmaY}
        }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
